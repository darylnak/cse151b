{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fashion_mnist_dataset.utils import mnist_reader\n",
    "import numpy as np\n",
    "\n",
    "def normalize(data):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "                Returns the min-max normalized data.\n",
    "    Parameters:  \n",
    "                data: array_like\n",
    "                    Data to be normalized.\n",
    "    Returns:\n",
    "                normData: ndarray\n",
    "                    Normalized data.\n",
    "    \"\"\"\n",
    "    minVal = np.amin(data)\n",
    "    maxVal = np.amax(data)\n",
    "    \n",
    "    normData = data - minVal\n",
    "    normData = normData/(maxVal - minVal)\n",
    "    \n",
    "    return normData\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "                Returns the one-hot encoding for a set of labels.\n",
    "    Parameters:  \n",
    "                labels: array_like\n",
    "                    Labels to be one-hot encoded.\n",
    "    Returns:\n",
    "                oneHot: ndarray\n",
    "                    One-hot encoded labels that is numData X numLabels.\n",
    "    \"\"\"\n",
    "    numLabels = np.amax(labels) - np.amin(labels) + 1\n",
    "    oneHot = np.zeros((labels.shape[0], numLabels))\n",
    "    \n",
    "    # See https://numpy.org/devdocs/user/basics.indexing.html#indexing-multi-dimensional-arrays\n",
    "    oneHot[np.array(range(labels.shape[0])), labels] = 1\n",
    "    \n",
    "    return oneHot\n",
    "\n",
    "def shuffle(data, labels):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "                Shuffle the data while maintaining proper labeling.\n",
    "    Parameters: \n",
    "                data: array_like\n",
    "                    Data to be shuffled.\n",
    "                labels: array_like\n",
    "                    Labels for each data point.\n",
    "    Returns:\n",
    "                dataShuffle: ndarray\n",
    "                    The shuffled data.\n",
    "                labelShuffle: ndarray\n",
    "                    The proper labels for the shuffled data.\n",
    "    \"\"\"\n",
    "    randIdxs = np.random.rand(data.shape[0]).argsort()\n",
    "    dataShuffle  = np.take(data, randIdxs, axis=0)\n",
    "    labelShuffle = np.take(labels, randIdxs, axis=0)\n",
    "    \n",
    "    return dataShuffle, labelShuffle\n",
    "\n",
    "def pca(data, comps):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "                Performs dimensionality reduction on data using Principle Component Analysis and returns the top comps PC's\n",
    "    Parameters:  \n",
    "                data: array_like\n",
    "                    Data to perform PCA on.\n",
    "                comps: int\n",
    "                    Number of components to return\n",
    "    Returns:\n",
    "                k_pcs: ndarray\n",
    "                    The top k principle components.\n",
    "    \"\"\"\n",
    "    # using procedure from slide 18: https://piazza.com/class_profile/get_resource/kfrlkk85pei2ma/kg1qafsrf721vt\n",
    "    mean = np.mean(data, axis=0)\n",
    "    A = data - mean\n",
    "    C = np.cov(A.T) # np.cov assumes columns are observations by default\n",
    "    \n",
    "    # returns e_vals in ascending order, e_vecs as column vectors\n",
    "    # we use eigh becuase C is symmetric (faster runtime)\n",
    "    e_vals, e_vecs = np.linalg.eigh(C)\n",
    "    k_pcs = e_vecs[:,-comps:]\n",
    "\n",
    "    return k_pcs\n",
    "\n",
    "def get_folds(data, k):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "                Returns the indices from the data set of training and test data\n",
    "                for k-folds cross validation.\n",
    "    Parameters:  \n",
    "                data: array_like\n",
    "                   Data set to split.\n",
    "                k: int\n",
    "                    Number of folds.\n",
    "    Returns:\n",
    "                folds: list\n",
    "                    Contains a list of array pairs <train, test> that are the \n",
    "                    indicies from the data set for training and testing.\n",
    "    \"\"\"\n",
    "    folds = []\n",
    "    \n",
    "    size = int(data.shape[0]/k) # size of each fold\n",
    "    for i in range(0, data.shape[0], size):\n",
    "        train = list(range(i)) + list(range(i+size, data.shape[0]))\n",
    "        test  = list(range(i, i+size))\n",
    "        folds.append((train, test))\n",
    "    \n",
    "    return folds\n",
    "\n",
    "def getData(X, y, classes):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "                Returns data for specific classes indicated from provided data.\n",
    "    Parameters:  \n",
    "                X: array_like\n",
    "                    The original dataset.\n",
    "                y: array_like\n",
    "                    The labels for each data point in the dataset.\n",
    "                classes: array_like\n",
    "                    Labels of the classes desired.\n",
    "    Returns:\n",
    "                new_data:\n",
    "                    Data for the classes specified by classes.\n",
    "                new_labels:\n",
    "                    Labels for the classes specified by classes.\n",
    "    \"\"\"\n",
    "    new_data   = []\n",
    "    new_labels = []\n",
    "\n",
    "    for label in classes:\n",
    "        # see the following link for more information: https://numpy.org/doc/stable/reference/generated/numpy.argwhere.html\n",
    "        # .T[0] is because argwhere() returns a column vector and we need normal array to index data\n",
    "        idxs = np.argwhere(y==label).T[0]\n",
    "        new_data.append(X[idxs])\n",
    "        new_labels.append(y[idxs])\n",
    "    \n",
    "    new_data   = np.vstack(new_data)\n",
    "    new_labels = np.hstack(new_labels)\n",
    "\n",
    "    return new_data, new_labels\n",
    "\n",
    "def prepareData(X, k_pcs, fold):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "                Prepares the data for training by performing k mutex splits, \n",
    "                PCA, and adding a bias term to the data. \n",
    "    Parameters:  \n",
    "                X: array_like\n",
    "                    The original dataset.\n",
    "                k_pcs: array_like\n",
    "                    The top k principal components of the dataset.\n",
    "    Returns:\n",
    "                train_set: array_like\n",
    "                    Data ready for training.\n",
    "                val_set: array_like\n",
    "                    Data ready for validation testing.\n",
    "    \"\"\"\n",
    "    train_set = X[fold[0]]@k_pcs # get training, reduce using PCA\n",
    "    train_set = np.hstack((np.ones((train_set.shape[0], 1)), train_set)) # add bias\n",
    "    \n",
    "    val_set   = X[fold[1]]@k_pcs # get validation, reduce using PCA\n",
    "    val_set   = np.hstack((np.ones((val_set.shape[0], 1)), val_set)) # add bias\n",
    "    \n",
    "    \n",
    "    return train_set, val_set\n",
    "\n",
    "def logisticRegression(data, labels):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "                TODO Trains a prediction model using x_train, y_train\n",
    "    Parameters:  \n",
    "                data: array_like\n",
    "                    Training examples.\n",
    "                labels: array_like\n",
    "                    Labels of the training examples.\n",
    "    Returns:\n",
    "                model: array_like\n",
    "                    The best model from training used for prediction.\n",
    "    \"\"\"\n",
    "    LR = .01 # Learning rate\n",
    "    BS = 512 # Batch Size\n",
    "    p  = 50  # top p PC's\n",
    "    k  = 4   # number of folds\n",
    "    M  = 100 # number of epochs\n",
    "    classes = [0, 9] # classes we want for binary classification\n",
    "    model   = None # best model from training\n",
    "    \n",
    "    X_train, y_train = getData(data, labels, classes)\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "    folds = get_folds(X_train, k=k)\n",
    "    k_pcs = pca(data, comps=p)\n",
    "    W = np.random.rand(X_train.shape[0], p+1) # initialize weights\n",
    "    \n",
    "    for fold in folds:\n",
    "        train_set, val_set = prepareData(X_train, k_pcs, fold)\n",
    "        \n",
    "        for epoch in range(M):\n",
    "            continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 50)\n",
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-09456a4eb059>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mX_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-140050fa538c>\u001b[0m in \u001b[0;36mlogisticRegression\u001b[0;34m(data, labels)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepareData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_pcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    X_train, y_train = mnist_reader.load_mnist('fashion_mnist_dataset/data/fashion', kind='train')\n",
    "    X_test, y_test   = mnist_reader.load_mnist('fashion_mnist_dataset/data/fashion', kind='t10k')\n",
    "    \n",
    "    # min-max normalize\n",
    "    X_train = normalize(X_train)\n",
    "    X_test  = normalize(X_test)\n",
    "    \n",
    "    model = logisticRegression(X_train, y_train)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
